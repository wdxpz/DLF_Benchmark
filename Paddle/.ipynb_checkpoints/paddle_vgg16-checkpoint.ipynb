{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import numpy\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def vgg_bn_drop(input):\n",
    "    def conv_block(ipt, num_filter, groups, dropouts):\n",
    "        return fluid.nets.img_conv_group(\n",
    "            input=ipt,\n",
    "            pool_size=2,\n",
    "            pool_stride=2,\n",
    "            conv_num_filter=[num_filter] * groups,\n",
    "            conv_filter_size=3,\n",
    "            conv_act='relu',\n",
    "            conv_with_batchnorm=True,\n",
    "            conv_batchnorm_drop_rate=dropouts,\n",
    "            pool_type='max')\n",
    "\n",
    "    conv1 = conv_block(input, 64, 2, [0.3, 0])\n",
    "    conv2 = conv_block(conv1, 128, 2, [0.4, 0])\n",
    "    conv3 = conv_block(conv2, 256, 3, [0.4, 0.4, 0])\n",
    "    conv4 = conv_block(conv3, 512, 3, [0.4, 0.4, 0])\n",
    "    conv5 = conv_block(conv4, 512, 3, [0.4, 0.4, 0])\n",
    "\n",
    "    drop = fluid.layers.dropout(x=conv5, dropout_prob=0.5)\n",
    "    fc1 = fluid.layers.fc(input=drop, size=512, act=None)\n",
    "    bn = fluid.layers.batch_norm(input=fc1, act='relu')\n",
    "    drop2 = fluid.layers.dropout(x=bn, dropout_prob=0.5)\n",
    "    fc2 = fluid.layers.fc(input=drop2, size=512, act=None)\n",
    "    predict = fluid.layers.fc(input=fc2, size=10, act='softmax')\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_program():\n",
    "    # The image is 32 * 32 with RGB representation.\n",
    "    data_shape = [3, 32, 32]\n",
    "    images = fluid.layers.data(name='pixel', shape=data_shape, dtype='float32')\n",
    "\n",
    "    predict = vgg_bn_drop(images)\n",
    "    # predict = vgg_bn_drop(images) # un-comment to use vgg net\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_program():\n",
    "    predict = inference_program()\n",
    "\n",
    "    label = fluid.layers.data(name='label', shape=[1], dtype='int64')\n",
    "    cost = fluid.layers.cross_entropy(input=predict, label=label)\n",
    "    avg_cost = fluid.layers.mean(cost)\n",
    "    accuracy = fluid.layers.accuracy(input=predict, label=label)\n",
    "    return [avg_cost, accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_program():\n",
    "    return fluid.optimizer.Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each batch will yield 32 images\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Reader for training\n",
    "# image pixels in [0, 1] and label in [0, 99].\n",
    "train_reader = paddle.batch(\n",
    "    paddle.reader.shuffle(paddle.dataset.cifar.train10(), buf_size=50000),\n",
    "    batch_size=BATCH_SIZE)\n",
    "\n",
    "# Reader for testing. A separated data set for testing.\n",
    "test_reader = paddle.batch(\n",
    "    paddle.dataset.cifar.test10(), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\n",
    "\n",
    "feed_order = ['pixel', 'label']\n",
    "\n",
    "main_program = fluid.default_main_program()\n",
    "star_program = fluid.default_startup_program()\n",
    "\n",
    "avg_cost, acc = train_program()\n",
    "\n",
    "# Test program\n",
    "test_program = main_program.clone(for_test=True)\n",
    "\n",
    "optimizer = optimizer_program()\n",
    "optimizer.minimize(avg_cost)\n",
    "\n",
    "exe = fluid.Executor(place)\n",
    "\n",
    "EPOCH_NUM = 30\n",
    "\n",
    "# For training test cost\n",
    "def train_test(program, reader):\n",
    "    count = 0\n",
    "    feed_var_list = [\n",
    "        program.global_block().var(var_name) for var_name in feed_order\n",
    "    ]\n",
    "    feeder_test = fluid.DataFeeder(\n",
    "        feed_list=feed_var_list, place=place)\n",
    "    test_exe = fluid.Executor(place)\n",
    "    accumulated = len([avg_cost, acc]) * [0]\n",
    "    for tid, test_data in enumerate(reader()):\n",
    "        avg_cost_np = test_exe.run(program=program,\n",
    "                                   feed=feeder_test.feed(test_data),\n",
    "                                   fetch_list=[avg_cost, acc])\n",
    "        accumulated = [x[0] + x[1][0] for x in zip(accumulated, avg_cost_np)]\n",
    "        count += 1\n",
    "    return [x / count for x in accumulated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dirname = \"model/image_classification_vgg.inference.model\"\n",
    "\n",
    "from paddle.utils.plot import Ploter\n",
    "import time\n",
    "\n",
    "train_prompt = \"Train cost\"\n",
    "test_prompt = \"Test cost\"\n",
    "plot_cost = Ploter(test_prompt,train_prompt)\n",
    "RESULT_FILE = 'result/results_vgg16.txt'\n",
    "\n",
    "EPOCH_NUM = 30\n",
    "print_every = 200\n",
    "# main train loop.\n",
    "def train_loop():\n",
    "    feed_var_list_loop = [\n",
    "        main_program.global_block().var(var_name) for var_name in feed_order\n",
    "    ]\n",
    "    feeder = fluid.DataFeeder(\n",
    "        feed_list=feed_var_list_loop, place=place)\n",
    "    exe.run(star_program)\n",
    "\n",
    "    \n",
    "    \n",
    "    start_time = time.time()\n",
    "    for pass_id in range(EPOCH_NUM):\n",
    "        average_loss = 0\n",
    "        step = 1\n",
    "        for step_id, data_train in enumerate(train_reader()):\n",
    "            avg_loss_value = exe.run(main_program,\n",
    "                                     feed=feeder.feed(data_train),\n",
    "                                     fetch_list=[avg_cost, acc])\n",
    "            average_loss += avg_loss_value[0]\n",
    "            if step % print_every == 0:\n",
    "#                 plot_cost.append(train_prompt, step, avg_loss_value[0])\n",
    "#                 plot_cost.plot()\n",
    "                average_loss = average_loss /print_every\n",
    "                print('[epoch: %3d, step: %5d] loss: %.3f' % (pass_id + 1, step, average_loss))\n",
    "                average_loss = 0\n",
    "            step += 1\n",
    "            \n",
    "    total_time = time.time() - start_time\n",
    "    with open(RESULT_FILE, 'a') as f:\n",
    "        f.write('\\n\\n\\ntraining results: \\n')\n",
    "        f.write('\\n total training time: \\t {}'.format(total_time))\n",
    "        f.write('\\n final average training lostt: \\t %.3f' % (average_loss))\n",
    "\n",
    "    start_time = time.time()\n",
    "    avg_cost_test, accuracy_test = train_test(test_program, reader=test_reader)\n",
    "    total_time = time.time() - start_time\n",
    "#     plot_cost.append(test_prompt, step, avg_cost_test)\n",
    "    s = '\\ntesting results: \\n accuracy on 1000 test images: %.3f, total time: %d s\\n' % (accuracy_test, total_time)\n",
    "    print(s)\n",
    "    with open(RESULT_FILE, 'a') as f:\n",
    "        f.write(s)\n",
    "\n",
    "    # save parameters\n",
    "#     if params_dirname is not None:\n",
    "#         fluid.io.save_inference_model(params_dirname, [\"pixel\"],\n",
    "#                                         [predict], exe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:   1, step:   200] loss: 2.329\n",
      "[epoch:   1, step:   400] loss: 2.109\n",
      "[epoch:   1, step:   600] loss: 1.966\n",
      "[epoch:   2, step:   200] loss: 1.849\n",
      "[epoch:   2, step:   400] loss: 1.795\n",
      "[epoch:   2, step:   600] loss: 1.743\n",
      "[epoch:   3, step:   200] loss: 1.622\n",
      "[epoch:   3, step:   400] loss: 1.565\n",
      "[epoch:   3, step:   600] loss: 1.517\n",
      "[epoch:   4, step:   200] loss: 1.463\n",
      "[epoch:   4, step:   400] loss: 1.410\n",
      "[epoch:   4, step:   600] loss: 1.380\n",
      "[epoch:   5, step:   200] loss: 1.308\n",
      "[epoch:   5, step:   400] loss: 1.268\n",
      "[epoch:   5, step:   600] loss: 1.236\n",
      "[epoch:   6, step:   200] loss: 1.192\n",
      "[epoch:   6, step:   400] loss: 1.148\n",
      "[epoch:   6, step:   600] loss: 1.137\n",
      "[epoch:   7, step:   200] loss: 1.074\n",
      "[epoch:   7, step:   400] loss: 1.079\n",
      "[epoch:   7, step:   600] loss: 1.080\n",
      "[epoch:   8, step:   200] loss: 1.009\n",
      "[epoch:   8, step:   400] loss: 1.003\n",
      "[epoch:   8, step:   600] loss: 0.986\n",
      "[epoch:   9, step:   200] loss: 0.946\n",
      "[epoch:   9, step:   400] loss: 0.963\n",
      "[epoch:   9, step:   600] loss: 0.929\n",
      "[epoch:  10, step:   200] loss: 0.907\n",
      "[epoch:  10, step:   400] loss: 0.888\n",
      "[epoch:  10, step:   600] loss: 0.863\n",
      "[epoch:  11, step:   200] loss: 0.837\n",
      "[epoch:  11, step:   400] loss: 0.854\n",
      "[epoch:  11, step:   600] loss: 0.842\n",
      "[epoch:  12, step:   200] loss: 0.811\n",
      "[epoch:  12, step:   400] loss: 0.788\n",
      "[epoch:  12, step:   600] loss: 0.790\n",
      "[epoch:  13, step:   200] loss: 0.757\n",
      "[epoch:  13, step:   400] loss: 0.755\n",
      "[epoch:  13, step:   600] loss: 0.743\n",
      "[epoch:  14, step:   200] loss: 0.742\n",
      "[epoch:  14, step:   400] loss: 0.712\n",
      "[epoch:  14, step:   600] loss: 0.719\n",
      "[epoch:  15, step:   200] loss: 0.708\n",
      "[epoch:  15, step:   400] loss: 0.676\n",
      "[epoch:  15, step:   600] loss: 0.681\n",
      "[epoch:  16, step:   200] loss: 0.654\n",
      "[epoch:  16, step:   400] loss: 0.675\n",
      "[epoch:  16, step:   600] loss: 0.647\n",
      "[epoch:  17, step:   200] loss: 0.617\n",
      "[epoch:  17, step:   400] loss: 0.619\n",
      "[epoch:  17, step:   600] loss: 0.626\n",
      "[epoch:  18, step:   200] loss: 0.615\n",
      "[epoch:  18, step:   400] loss: 0.600\n",
      "[epoch:  18, step:   600] loss: 0.612\n",
      "[epoch:  19, step:   200] loss: 0.573\n",
      "[epoch:  19, step:   400] loss: 0.585\n",
      "[epoch:  19, step:   600] loss: 0.577\n",
      "[epoch:  20, step:   200] loss: 0.559\n",
      "[epoch:  20, step:   400] loss: 0.555\n",
      "[epoch:  20, step:   600] loss: 0.560\n",
      "[epoch:  21, step:   200] loss: 0.517\n",
      "[epoch:  21, step:   400] loss: 0.532\n",
      "[epoch:  21, step:   600] loss: 0.532\n",
      "[epoch:  22, step:   200] loss: 0.519\n",
      "[epoch:  22, step:   400] loss: 0.516\n",
      "[epoch:  22, step:   600] loss: 0.521\n",
      "[epoch:  23, step:   200] loss: 0.490\n",
      "[epoch:  23, step:   400] loss: 0.506\n",
      "[epoch:  23, step:   600] loss: 0.483\n",
      "[epoch:  24, step:   200] loss: 0.473\n",
      "[epoch:  24, step:   400] loss: 0.470\n",
      "[epoch:  24, step:   600] loss: 0.486\n",
      "[epoch:  25, step:   200] loss: 0.452\n",
      "[epoch:  25, step:   400] loss: 0.468\n",
      "[epoch:  25, step:   600] loss: 0.469\n",
      "[epoch:  26, step:   200] loss: 0.453\n",
      "[epoch:  26, step:   400] loss: 0.433\n",
      "[epoch:  26, step:   600] loss: 0.440\n",
      "[epoch:  27, step:   200] loss: 0.422\n",
      "[epoch:  27, step:   400] loss: 0.428\n",
      "[epoch:  27, step:   600] loss: 0.433\n",
      "[epoch:  28, step:   200] loss: 0.414\n",
      "[epoch:  28, step:   400] loss: 0.414\n",
      "[epoch:  28, step:   600] loss: 0.418\n",
      "[epoch:  29, step:   200] loss: 0.384\n",
      "[epoch:  29, step:   400] loss: 0.408\n",
      "[epoch:  29, step:   600] loss: 0.419\n",
      "[epoch:  30, step:   200] loss: 0.390\n",
      "[epoch:  30, step:   400] loss: 0.394\n",
      "[epoch:  30, step:   600] loss: 0.380\n",
      "\n",
      "testing results: \n",
      " accuracy on 1000 test images: 0.824, total time: 6 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:   1, step:   200] loss: 2.325\n",
      "[epoch:   1, step:   400] loss: 2.069\n",
      "[epoch:   1, step:   600] loss: 1.969\n",
      "[epoch:   2, step:   200] loss: 1.860\n",
      "[epoch:   2, step:   400] loss: 1.790\n",
      "[epoch:   2, step:   600] loss: 1.734\n",
      "[epoch:   3, step:   200] loss: 1.653\n",
      "[epoch:   3, step:   400] loss: 1.598\n",
      "[epoch:   3, step:   600] loss: 1.561\n",
      "[epoch:   4, step:   200] loss: 1.459\n",
      "[epoch:   4, step:   400] loss: 1.417\n",
      "[epoch:   4, step:   600] loss: 1.402\n",
      "[epoch:   5, step:   200] loss: 1.302\n",
      "[epoch:   5, step:   400] loss: 1.287\n",
      "[epoch:   5, step:   600] loss: 1.254\n",
      "[epoch:   6, step:   200] loss: 1.185\n",
      "[epoch:   6, step:   400] loss: 1.150\n",
      "[epoch:   6, step:   600] loss: 1.130\n",
      "[epoch:   7, step:   200] loss: 1.074\n",
      "[epoch:   7, step:   400] loss: 1.064\n",
      "[epoch:   7, step:   600] loss: 1.055\n",
      "[epoch:   8, step:   200] loss: 1.002\n",
      "[epoch:   8, step:   400] loss: 0.997\n",
      "[epoch:   8, step:   600] loss: 0.965\n",
      "[epoch:   9, step:   200] loss: 0.939\n",
      "[epoch:   9, step:   400] loss: 0.906\n",
      "[epoch:   9, step:   600] loss: 0.937\n",
      "[epoch:  10, step:   200] loss: 0.890\n",
      "[epoch:  10, step:   400] loss: 0.878\n",
      "[epoch:  10, step:   600] loss: 0.852\n",
      "[epoch:  11, step:   200] loss: 0.844\n",
      "[epoch:  11, step:   400] loss: 0.823\n",
      "[epoch:  11, step:   600] loss: 0.821\n",
      "[epoch:  12, step:   200] loss: 0.784\n",
      "[epoch:  12, step:   400] loss: 0.784\n",
      "[epoch:  12, step:   600] loss: 0.782\n",
      "[epoch:  13, step:   200] loss: 0.751\n",
      "[epoch:  13, step:   400] loss: 0.741\n",
      "[epoch:  13, step:   600] loss: 0.749\n",
      "[epoch:  14, step:   200] loss: 0.707\n",
      "[epoch:  14, step:   400] loss: 0.708\n",
      "[epoch:  14, step:   600] loss: 0.718\n",
      "[epoch:  15, step:   200] loss: 0.679\n",
      "[epoch:  15, step:   400] loss: 0.679\n",
      "[epoch:  15, step:   600] loss: 0.662\n",
      "[epoch:  16, step:   200] loss: 0.626\n",
      "[epoch:  16, step:   400] loss: 0.657\n",
      "[epoch:  16, step:   600] loss: 0.636\n",
      "[epoch:  17, step:   200] loss: 0.635\n",
      "[epoch:  17, step:   400] loss: 0.599\n",
      "[epoch:  17, step:   600] loss: 0.615\n",
      "[epoch:  18, step:   200] loss: 0.583\n",
      "[epoch:  18, step:   400] loss: 0.594\n",
      "[epoch:  18, step:   600] loss: 0.593\n",
      "[epoch:  19, step:   200] loss: 0.566\n",
      "[epoch:  19, step:   400] loss: 0.565\n",
      "[epoch:  19, step:   600] loss: 0.552\n",
      "[epoch:  20, step:   200] loss: 0.536\n",
      "[epoch:  20, step:   400] loss: 0.546\n",
      "[epoch:  20, step:   600] loss: 0.555\n",
      "[epoch:  21, step:   200] loss: 0.510\n",
      "[epoch:  21, step:   400] loss: 0.517\n",
      "[epoch:  21, step:   600] loss: 0.530\n",
      "[epoch:  22, step:   200] loss: 0.488\n",
      "[epoch:  22, step:   400] loss: 0.507\n",
      "[epoch:  22, step:   600] loss: 0.509\n",
      "[epoch:  23, step:   200] loss: 0.478\n",
      "[epoch:  23, step:   400] loss: 0.507\n",
      "[epoch:  23, step:   600] loss: 0.474\n",
      "[epoch:  24, step:   200] loss: 0.468\n",
      "[epoch:  24, step:   400] loss: 0.453\n",
      "[epoch:  24, step:   600] loss: 0.465\n",
      "[epoch:  25, step:   200] loss: 0.455\n",
      "[epoch:  25, step:   400] loss: 0.437\n",
      "[epoch:  25, step:   600] loss: 0.447\n",
      "[epoch:  26, step:   200] loss: 0.438\n",
      "[epoch:  26, step:   400] loss: 0.434\n",
      "[epoch:  26, step:   600] loss: 0.435\n",
      "[epoch:  27, step:   200] loss: 0.410\n",
      "[epoch:  27, step:   400] loss: 0.423\n",
      "[epoch:  27, step:   600] loss: 0.431\n",
      "[epoch:  28, step:   200] loss: 0.385\n",
      "[epoch:  28, step:   400] loss: 0.426\n",
      "[epoch:  28, step:   600] loss: 0.395\n",
      "[epoch:  29, step:   200] loss: 0.390\n",
      "[epoch:  29, step:   400] loss: 0.391\n",
      "[epoch:  29, step:   600] loss: 0.384\n",
      "[epoch:  30, step:   200] loss: 0.370\n",
      "[epoch:  30, step:   400] loss: 0.373\n",
      "[epoch:  30, step:   600] loss: 0.378\n",
      "\n",
      "testing results: \n",
      " accuracy on 1000 test images: 0.797, total time: 6 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:   1, step:   200] loss: 2.378\n",
      "[epoch:   1, step:   400] loss: 2.130\n",
      "[epoch:   1, step:   600] loss: 1.988\n",
      "[epoch:   2, step:   200] loss: 1.857\n",
      "[epoch:   2, step:   400] loss: 1.784\n",
      "[epoch:   2, step:   600] loss: 1.730\n",
      "[epoch:   3, step:   200] loss: 1.618\n",
      "[epoch:   3, step:   400] loss: 1.561\n",
      "[epoch:   3, step:   600] loss: 1.515\n",
      "[epoch:   4, step:   200] loss: 1.432\n",
      "[epoch:   4, step:   400] loss: 1.374\n",
      "[epoch:   4, step:   600] loss: 1.349\n",
      "[epoch:   5, step:   200] loss: 1.258\n",
      "[epoch:   5, step:   400] loss: 1.237\n",
      "[epoch:   5, step:   600] loss: 1.211\n",
      "[epoch:   6, step:   200] loss: 1.149\n",
      "[epoch:   6, step:   400] loss: 1.146\n",
      "[epoch:   6, step:   600] loss: 1.127\n",
      "[epoch:   7, step:   200] loss: 1.050\n",
      "[epoch:   7, step:   400] loss: 1.067\n",
      "[epoch:   7, step:   600] loss: 1.044\n",
      "[epoch:   8, step:   200] loss: 1.002\n",
      "[epoch:   8, step:   400] loss: 0.988\n",
      "[epoch:   8, step:   600] loss: 0.964\n",
      "[epoch:   9, step:   200] loss: 0.922\n",
      "[epoch:   9, step:   400] loss: 0.932\n",
      "[epoch:   9, step:   600] loss: 0.907\n",
      "[epoch:  10, step:   200] loss: 0.862\n",
      "[epoch:  10, step:   400] loss: 0.876\n",
      "[epoch:  10, step:   600] loss: 0.848\n",
      "[epoch:  11, step:   200] loss: 0.822\n",
      "[epoch:  11, step:   400] loss: 0.813\n",
      "[epoch:  11, step:   600] loss: 0.808\n",
      "[epoch:  12, step:   200] loss: 0.786\n",
      "[epoch:  12, step:   400] loss: 0.768\n",
      "[epoch:  12, step:   600] loss: 0.779\n",
      "[epoch:  13, step:   200] loss: 0.748\n",
      "[epoch:  13, step:   400] loss: 0.726\n",
      "[epoch:  13, step:   600] loss: 0.729\n",
      "[epoch:  14, step:   200] loss: 0.718\n",
      "[epoch:  14, step:   400] loss: 0.717\n",
      "[epoch:  14, step:   600] loss: 0.699\n",
      "[epoch:  15, step:   200] loss: 0.663\n",
      "[epoch:  15, step:   400] loss: 0.675\n",
      "[epoch:  15, step:   600] loss: 0.679\n",
      "[epoch:  16, step:   200] loss: 0.634\n",
      "[epoch:  16, step:   400] loss: 0.657\n",
      "[epoch:  16, step:   600] loss: 0.640\n",
      "[epoch:  17, step:   200] loss: 0.611\n",
      "[epoch:  17, step:   400] loss: 0.618\n",
      "[epoch:  17, step:   600] loss: 0.622\n",
      "[epoch:  18, step:   200] loss: 0.593\n",
      "[epoch:  18, step:   400] loss: 0.609\n",
      "[epoch:  18, step:   600] loss: 0.591\n",
      "[epoch:  19, step:   200] loss: 0.593\n",
      "[epoch:  19, step:   400] loss: 0.572\n",
      "[epoch:  19, step:   600] loss: 0.573\n",
      "[epoch:  20, step:   200] loss: 0.524\n",
      "[epoch:  20, step:   400] loss: 0.566\n",
      "[epoch:  20, step:   600] loss: 0.548\n",
      "[epoch:  21, step:   200] loss: 0.519\n",
      "[epoch:  21, step:   400] loss: 0.527\n",
      "[epoch:  21, step:   600] loss: 0.520\n",
      "[epoch:  22, step:   200] loss: 0.498\n",
      "[epoch:  22, step:   400] loss: 0.506\n",
      "[epoch:  22, step:   600] loss: 0.508\n",
      "[epoch:  23, step:   200] loss: 0.491\n",
      "[epoch:  23, step:   400] loss: 0.491\n",
      "[epoch:  23, step:   600] loss: 0.487\n",
      "[epoch:  24, step:   200] loss: 0.467\n",
      "[epoch:  24, step:   400] loss: 0.464\n",
      "[epoch:  24, step:   600] loss: 0.493\n",
      "[epoch:  25, step:   200] loss: 0.456\n",
      "[epoch:  25, step:   400] loss: 0.458\n",
      "[epoch:  25, step:   600] loss: 0.451\n",
      "[epoch:  26, step:   200] loss: 0.434\n",
      "[epoch:  26, step:   400] loss: 0.437\n",
      "[epoch:  26, step:   600] loss: 0.442\n",
      "[epoch:  27, step:   200] loss: 0.420\n",
      "[epoch:  27, step:   400] loss: 0.426\n",
      "[epoch:  27, step:   600] loss: 0.430\n",
      "[epoch:  28, step:   200] loss: 0.412\n",
      "[epoch:  28, step:   400] loss: 0.418\n",
      "[epoch:  28, step:   600] loss: 0.413\n",
      "[epoch:  29, step:   200] loss: 0.393\n",
      "[epoch:  29, step:   400] loss: 0.395\n",
      "[epoch:  29, step:   600] loss: 0.398\n",
      "[epoch:  30, step:   200] loss: 0.381\n",
      "[epoch:  30, step:   400] loss: 0.385\n",
      "[epoch:  30, step:   600] loss: 0.379\n",
      "\n",
      "testing results: \n",
      " accuracy on 1000 test images: 0.819, total time: 6 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
