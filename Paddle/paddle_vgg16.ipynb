{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import numpy\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each batch will yield 32 images\n",
    "BATCH_SIZE = 128\n",
    "EPOCH_NUM = 30\n",
    "lr = 0.0001\n",
    "\n",
    "use_cuda = True\n",
    "place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def vgg_bn_drop(input):\n",
    "    def conv_block(ipt, num_filter, groups, dropouts):\n",
    "        return fluid.nets.img_conv_group(\n",
    "            input=ipt,\n",
    "            pool_size=2,\n",
    "            pool_stride=2,\n",
    "            conv_num_filter=[num_filter] * groups,\n",
    "            conv_filter_size=3,\n",
    "            conv_act='relu',\n",
    "            conv_with_batchnorm=True,\n",
    "            conv_batchnorm_drop_rate=dropouts,\n",
    "            pool_type='max')\n",
    "\n",
    "    conv1 = conv_block(input, 64, 2, [0.3, 0])\n",
    "    conv2 = conv_block(conv1, 128, 2, [0.4, 0])\n",
    "    conv3 = conv_block(conv2, 256, 3, [0.4, 0.4, 0])\n",
    "    conv4 = conv_block(conv3, 512, 3, [0.4, 0.4, 0])\n",
    "    conv5 = conv_block(conv4, 512, 3, [0.4, 0.4, 0])\n",
    "\n",
    "    drop = fluid.layers.dropout(x=conv5, dropout_prob=0.5)\n",
    "    fc1 = fluid.layers.fc(input=drop, size=512, act=None)\n",
    "    bn = fluid.layers.batch_norm(input=fc1, act='relu')\n",
    "    drop2 = fluid.layers.dropout(x=bn, dropout_prob=0.5)\n",
    "    fc2 = fluid.layers.fc(input=drop2, size=512, act=None)\n",
    "    predict = fluid.layers.fc(input=fc2, size=10, act='softmax')\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_program():\n",
    "    # The image is 32 * 32 with RGB representation.\n",
    "    data_shape = [3, 32, 32]\n",
    "    images = fluid.layers.data(name='pixel', shape=data_shape, dtype='float32')\n",
    "\n",
    "    predict = vgg_bn_drop(images)\n",
    "    # predict = vgg_bn_drop(images) # un-comment to use vgg net\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_program():\n",
    "    predict = inference_program()\n",
    "\n",
    "    label = fluid.layers.data(name='label', shape=[1], dtype='int64')\n",
    "    cost = fluid.layers.cross_entropy(input=predict, label=label)\n",
    "    avg_cost = fluid.layers.mean(cost)\n",
    "    accuracy = fluid.layers.accuracy(input=predict, label=label)\n",
    "    return [avg_cost, accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_program():\n",
    "    return fluid.optimizer.Adam(learning_rate=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file 2ec5301f8df486a1d3decedc8f708bd6  md5 c58f30108f718f92721af3b95e74349a\n",
      "Cache file /root/.cache/paddle/dataset/cifar/cifar-10-python.tar.gz not found, downloading https://dataset.bj.bcebos.com/cifar/cifar-10-python.tar.gz \n",
      "Begin to download\n",
      "....................\n",
      "Download finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Reader for training\n",
    "# image pixels in [0, 1] and label in [0, 99].\n",
    "train_reader = paddle.batch(\n",
    "    paddle.reader.shuffle(paddle.dataset.cifar.train10(), buf_size=50000),\n",
    "    batch_size=BATCH_SIZE)\n",
    "\n",
    "# Reader for testing. A separated data set for testing.\n",
    "test_reader = paddle.batch(\n",
    "    paddle.dataset.cifar.test10(), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feed_order = ['pixel', 'label']\n",
    "\n",
    "main_program = fluid.default_main_program()\n",
    "star_program = fluid.default_startup_program()\n",
    "\n",
    "avg_cost, acc = train_program()\n",
    "\n",
    "# Test program\n",
    "test_program = main_program.clone(for_test=True)\n",
    "\n",
    "optimizer = optimizer_program()\n",
    "optimizer.minimize(avg_cost)\n",
    "\n",
    "exe = fluid.Executor(place)\n",
    "\n",
    "\n",
    "\n",
    "# For training test cost\n",
    "def train_test(program, reader):\n",
    "    count = 0\n",
    "    feed_var_list = [\n",
    "        program.global_block().var(var_name) for var_name in feed_order\n",
    "    ]\n",
    "    feeder_test = fluid.DataFeeder(\n",
    "        feed_list=feed_var_list, place=place)\n",
    "    test_exe = fluid.Executor(place)\n",
    "    accumulated = len([avg_cost, acc]) * [0]\n",
    "    for tid, test_data in enumerate(reader()):\n",
    "        avg_cost_np = test_exe.run(program=program,\n",
    "                                   feed=feeder_test.feed(test_data),\n",
    "                                   fetch_list=[avg_cost, acc])\n",
    "        accumulated = [x[0] + x[1][0] for x in zip(accumulated, avg_cost_np)]\n",
    "        count += 1\n",
    "    return [x / count for x in accumulated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-20 03:12:37,987-INFO: font search path ['/usr/local/lib/python2.7/dist-packages/matplotlib/mpl-data/fonts/ttf', '/usr/local/lib/python2.7/dist-packages/matplotlib/mpl-data/fonts/afm', '/usr/local/lib/python2.7/dist-packages/matplotlib/mpl-data/fonts/pdfcorefonts']\n",
      "2020-07-20 03:12:38,293-INFO: generated new fontManager\n"
     ]
    }
   ],
   "source": [
    "params_dirname = \"model/image_classification_vgg.inference.model\"\n",
    "\n",
    "from paddle.utils.plot import Ploter\n",
    "import time\n",
    "\n",
    "train_prompt = \"Train cost\"\n",
    "test_prompt = \"Test cost\"\n",
    "plot_cost = Ploter(test_prompt,train_prompt)\n",
    "RESULT_FILE = 'result/results_vgg16.txt'\n",
    "\n",
    "EPOCH_NUM = 30\n",
    "print_every = 200\n",
    "# main train loop.\n",
    "def train_loop():\n",
    "    feed_var_list_loop = [\n",
    "        main_program.global_block().var(var_name) for var_name in feed_order\n",
    "    ]\n",
    "    feeder = fluid.DataFeeder(\n",
    "        feed_list=feed_var_list_loop, place=place)\n",
    "    exe.run(star_program)\n",
    "\n",
    "    \n",
    "    \n",
    "    start_time = time.time()\n",
    "    for pass_id in range(EPOCH_NUM):\n",
    "        average_loss = 0\n",
    "        step = 1\n",
    "        for step_id, data_train in enumerate(train_reader()):\n",
    "            avg_loss_value = exe.run(main_program,\n",
    "                                     feed=feeder.feed(data_train),\n",
    "                                     fetch_list=[avg_cost, acc])\n",
    "            average_loss += avg_loss_value[0]\n",
    "            if step % print_every == 0:\n",
    "#                 plot_cost.append(train_prompt, step, avg_loss_value[0])\n",
    "#                 plot_cost.plot()\n",
    "                average_loss = average_loss /print_every\n",
    "                print('[epoch: %3d, step: %5d] loss: %.3f' % (pass_id + 1, step, average_loss))\n",
    "                average_loss = 0\n",
    "            step += 1\n",
    "            \n",
    "    total_time = time.time() - start_time\n",
    "    with open(RESULT_FILE, 'a') as f:\n",
    "        f.write('\\n\\n\\ntraining results: \\n')\n",
    "        f.write('\\n total training time: \\t {}'.format(total_time))\n",
    "        f.write('\\n final average training lostt: \\t %.3f' % (average_loss))\n",
    "\n",
    "    start_time = time.time()\n",
    "    avg_cost_test, accuracy_test = train_test(test_program, reader=test_reader)\n",
    "    total_time = time.time() - start_time\n",
    "#     plot_cost.append(test_prompt, step, avg_cost_test)\n",
    "    s = '\\ntesting results: \\n accuracy on 1000 test images: %.3f, total time: %d s\\n' % (accuracy_test, total_time)\n",
    "    print(s)\n",
    "    with open(RESULT_FILE, 'a') as f:\n",
    "        f.write(s)\n",
    "\n",
    "    # save parameters\n",
    "#     if params_dirname is not None:\n",
    "#         fluid.io.save_inference_model(params_dirname, [\"pixel\"],\n",
    "#                                         [predict], exe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:   1, step:   200] loss: 2.305\n",
      "[epoch:   2, step:   200] loss: 1.914\n",
      "[epoch:   3, step:   200] loss: 1.723\n",
      "[epoch:   4, step:   200] loss: 1.561\n",
      "[epoch:   5, step:   200] loss: 1.443\n",
      "[epoch:   6, step:   200] loss: 1.330\n",
      "[epoch:   7, step:   200] loss: 1.237\n",
      "[epoch:   8, step:   200] loss: 1.147\n",
      "[epoch:   9, step:   200] loss: 1.095\n",
      "[epoch:  10, step:   200] loss: 1.020\n",
      "[epoch:  11, step:   200] loss: 0.975\n",
      "[epoch:  12, step:   200] loss: 0.924\n",
      "[epoch:  13, step:   200] loss: 0.881\n",
      "[epoch:  14, step:   200] loss: 0.837\n",
      "[epoch:  15, step:   200] loss: 0.804\n",
      "[epoch:  16, step:   200] loss: 0.765\n",
      "[epoch:  17, step:   200] loss: 0.747\n",
      "[epoch:  18, step:   200] loss: 0.704\n",
      "[epoch:  19, step:   200] loss: 0.665\n",
      "[epoch:  20, step:   200] loss: 0.651\n",
      "[epoch:  21, step:   200] loss: 0.624\n",
      "[epoch:  22, step:   200] loss: 0.604\n",
      "[epoch:  23, step:   200] loss: 0.580\n",
      "[epoch:  24, step:   200] loss: 0.564\n",
      "[epoch:  25, step:   200] loss: 0.560\n",
      "[epoch:  26, step:   200] loss: 0.534\n",
      "[epoch:  27, step:   200] loss: 0.507\n",
      "[epoch:  28, step:   200] loss: 0.498\n",
      "[epoch:  29, step:   200] loss: 0.486\n",
      "[epoch:  30, step:   200] loss: 0.468\n",
      "\n",
      "testing results: \n",
      " accuracy on 1000 test images: 0.792, total time: 5 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:   1, step:   200] loss: 2.295\n",
      "[epoch:   2, step:   200] loss: 1.914\n",
      "[epoch:   3, step:   200] loss: 1.734\n",
      "[epoch:   4, step:   200] loss: 1.561\n",
      "[epoch:   5, step:   200] loss: 1.430\n",
      "[epoch:   6, step:   200] loss: 1.335\n",
      "[epoch:   7, step:   200] loss: 1.240\n",
      "[epoch:   8, step:   200] loss: 1.170\n",
      "[epoch:   9, step:   200] loss: 1.100\n",
      "[epoch:  10, step:   200] loss: 1.036\n",
      "[epoch:  11, step:   200] loss: 0.983\n",
      "[epoch:  12, step:   200] loss: 0.936\n",
      "[epoch:  13, step:   200] loss: 0.897\n",
      "[epoch:  14, step:   200] loss: 0.844\n",
      "[epoch:  15, step:   200] loss: 0.814\n",
      "[epoch:  16, step:   200] loss: 0.771\n",
      "[epoch:  17, step:   200] loss: 0.751\n",
      "[epoch:  18, step:   200] loss: 0.718\n",
      "[epoch:  19, step:   200] loss: 0.680\n",
      "[epoch:  20, step:   200] loss: 0.667\n",
      "[epoch:  21, step:   200] loss: 0.640\n",
      "[epoch:  22, step:   200] loss: 0.621\n",
      "[epoch:  23, step:   200] loss: 0.602\n",
      "[epoch:  24, step:   200] loss: 0.573\n",
      "[epoch:  25, step:   200] loss: 0.556\n",
      "[epoch:  26, step:   200] loss: 0.539\n",
      "[epoch:  27, step:   200] loss: 0.517\n",
      "[epoch:  28, step:   200] loss: 0.505\n",
      "[epoch:  29, step:   200] loss: 0.483\n",
      "[epoch:  30, step:   200] loss: 0.472\n",
      "\n",
      "testing results: \n",
      " accuracy on 1000 test images: 0.798, total time: 5 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:   1, step:   200] loss: 2.250\n",
      "[epoch:   2, step:   200] loss: 1.894\n",
      "[epoch:   3, step:   200] loss: 1.720\n",
      "[epoch:   4, step:   200] loss: 1.577\n",
      "[epoch:   5, step:   200] loss: 1.451\n",
      "[epoch:   6, step:   200] loss: 1.334\n",
      "[epoch:   7, step:   200] loss: 1.242\n",
      "[epoch:   8, step:   200] loss: 1.173\n",
      "[epoch:   9, step:   200] loss: 1.087\n",
      "[epoch:  10, step:   200] loss: 1.022\n",
      "[epoch:  11, step:   200] loss: 0.969\n",
      "[epoch:  12, step:   200] loss: 0.910\n",
      "[epoch:  13, step:   200] loss: 0.875\n",
      "[epoch:  14, step:   200] loss: 0.834\n",
      "[epoch:  15, step:   200] loss: 0.806\n",
      "[epoch:  16, step:   200] loss: 0.762\n",
      "[epoch:  17, step:   200] loss: 0.737\n",
      "[epoch:  18, step:   200] loss: 0.712\n",
      "[epoch:  19, step:   200] loss: 0.678\n",
      "[epoch:  20, step:   200] loss: 0.651\n",
      "[epoch:  21, step:   200] loss: 0.621\n",
      "[epoch:  22, step:   200] loss: 0.606\n",
      "[epoch:  23, step:   200] loss: 0.576\n",
      "[epoch:  24, step:   200] loss: 0.569\n",
      "[epoch:  25, step:   200] loss: 0.545\n",
      "[epoch:  26, step:   200] loss: 0.533\n",
      "[epoch:  27, step:   200] loss: 0.512\n",
      "[epoch:  28, step:   200] loss: 0.495\n",
      "[epoch:  29, step:   200] loss: 0.478\n",
      "[epoch:  30, step:   200] loss: 0.464\n",
      "\n",
      "testing results: \n",
      " accuracy on 1000 test images: 0.779, total time: 5 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
